{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10f78392-dbd4-4a8a-92cc-feafd9c918fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single device: GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import shutil\n",
    "import requests, json\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "botnum = 1\n",
    "bot = ['https://discord.com/api/webhooks/1162767976034996274/B6CjtQF1SzNRalG_csFx8-qJ5ODBoy5SBUelbGyl-v-QhYhwdsTfE59F-K-rXj3HyUh-',\n",
    "      'https://discord.com/api/webhooks/1162767979658887299/0TICfekiC9wjPmp-GqE5zrwU57q2RJHG2peel_KOYagUDYCjovYUfyNJmDR9jbD-WXoE']\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"GPU:0\")\n",
    "    print('Single device: GPU:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e72c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install jupyter-tabnine\n",
    "# !jupyter nbextension install --py jupyter_tabnine\n",
    "# !jupyter nbextension enable --py jupyter_tabnine\n",
    "# !jupyter serverextension enable --py jupyter_tabnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68fa64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscordNotificationCallback(Callback):\n",
    "    def __init__(self, webhook_url, interval=1):\n",
    "        super().__init__()\n",
    "        self.webhook_url = webhook_url\n",
    "        self.interval = interval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.interval == 0:\n",
    "            if logs is not None:\n",
    "                loss = logs.get('loss')\n",
    "                accuracy = logs.get('accuracy')\n",
    "                val_loss = logs.get('val_loss')\n",
    "                val_accuracy = logs.get('val_accuracy')\n",
    "                message = f\"LSTM-KDD -> Epoch: {epoch}, Loss: {loss}, Accuracy: {accuracy}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\"\n",
    "                payload = {\"content\": message}\n",
    "                headers = {\"Content-Type\": \"application/json\"}\n",
    "                response = requests.post(self.webhook_url, data=json.dumps(payload), headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c3eeef76-95a5-4401-a34e-71f98a679efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processlabel(df):\n",
    "    df.loc[df['label'] == 'normal', 'label'] = 0\n",
    "    df.loc[df['label'] != 0, 'label'] = 1\n",
    "    df['label'] = df['label'].astype('int')\n",
    "    return df\n",
    "    \n",
    "def preprocess(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "def send_discord_message(content):\n",
    "    webhook_url = bot[botnum]\n",
    "\n",
    "    data = {\n",
    "        'content': content\n",
    "    }\n",
    "\n",
    "    response = requests.post(webhook_url, data=json.dumps(data), headers={'Content-Type': 'application/json'})\n",
    "\n",
    "    if response.status_code != 204:\n",
    "        raise ValueError(f'Request to discord returned an error {response.status_code}, the response is:\\n{response.text}')\n",
    "\n",
    "def create_LSTM(n_input, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64,return_sequences=False, input_shape =(n_input, n_features)))\n",
    "    model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(256,return_sequences=True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(256,return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer ='adam', loss = 'BinaryCrossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4dffa985-a404-4d30-bbdd-a179b7c889e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dir = train_path.split('/')\n",
    "# df = pd.read_csv(f'./dataset/all_dataset/imap.csv')\n",
    "# df.label.value_counts()\n",
    "# df = processlabel(df)\n",
    "\n",
    "# X = df.drop(['label'], axis =1)\n",
    "# X = preprocess(X)\n",
    "# y = df['label']\n",
    "\n",
    "# window_size = 128\n",
    "# n_features = 41\n",
    "# train_size = int(len(X) * 0.7)\n",
    "\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# train_generator = TimeseriesGenerator(X_train, y_train, length = window_size, batch_size =8)\n",
    "# train_generator = TimeseriesGenerator(X_test, y_test, length = window_size, batch_size =8)\n",
    "\n",
    "# model = create_LSTM(window_size, n_features)\n",
    "# model.summary()\n",
    "# model.fit(generator, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3198e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/kdd/')\n",
    "df_list = glob.glob('/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/kdd/dataset/all_dataset/*.csv')\n",
    "dataset = {}\n",
    "\n",
    "model_path = './model'\n",
    "csv_path = './results'\n",
    "if not os.path.exists(model_path):\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(model_path)\n",
    "   print(f\"The {model_path} directory is created!\")\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(csv_path)\n",
    "   print(f\"The {csv_path} directory is created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5d0f880-3e44-4363-9616-6839e1578dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 64)                27136     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27201 (106.25 KB)\n",
      "Trainable params: 27201 (106.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "5265/6742 [======================>.......] - ETA: 45s - loss: 0.0011"
     ]
    }
   ],
   "source": [
    "\n",
    "#Training and evaluation\n",
    "\n",
    "for train_path in df_list:\n",
    "\n",
    "   #Loading Dataset & Preprocess\n",
    "   dir = train_path.split('/')\n",
    "   df = pd.read_csv(f'./dataset/all_dataset/{dir[-1]}')\n",
    "   df = processlabel(df)\n",
    "    \n",
    "   X = df.drop(['label'], axis =1)\n",
    "   X = preprocess(X)\n",
    "   y = df['label']\n",
    "\n",
    "   #Creating callbacks\n",
    "   save_model_path = f'{model_path}/{train_path}.ckpt'\n",
    "\n",
    "   discord_callback = DiscordNotificationCallback(bot[botnum], interval=1)\n",
    "   earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "   best_model = ModelCheckpoint(save_model_path, save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "   #Setting parameter\n",
    "   window_size = 128\n",
    "   n_features = 41\n",
    "   train_size = int(len(X) * 0.7)\n",
    "    \n",
    "   X_train, X_test = X[:train_size], X[train_size:]\n",
    "   y_train, y_test = y[:train_size], y[train_size:]\n",
    "   \n",
    "   train_generator = TimeseriesGenerator(X_train, y_train, length = window_size, batch_size =8)\n",
    "   test_generator = TimeseriesGenerator(X_test, y_test, length = window_size, batch_size =8)\n",
    "    \n",
    "   model = create_LSTM(window_size, n_features)\n",
    "\n",
    "   #Summary of Model\n",
    "   model.summary()\n",
    "   # try:\n",
    "   model.fit(train_generator, \n",
    "            epochs=100,\n",
    "            callbacks= [discord_callback, best_model, earlyStopping],\n",
    "            validation_data=(X_test, y_test))  \n",
    "   \n",
    "   evaluation_model = create_LSTM(window_size, n_features)\n",
    "   evaluation_model.load_weights(save_model_path)\n",
    "\n",
    "   # Evaluate the model on the test set\n",
    "   y_pred_test = evaluation_model.predict_classes(X_test)\n",
    "   y_pred_prob_test = evaluation_model.predict(X_test)\n",
    "\n",
    "   accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "   f1_test = f1_score(y_test, y_pred_test)\n",
    "   precision_test = precision_score(y_test, y_pred_test)\n",
    "   recall_test = recall_score(y_test, y_pred_test)\n",
    "   loss_test = log_loss(y_test, y_pred_prob_test)\n",
    "\n",
    "   # Save results\n",
    "   results = {\n",
    "      \"accuracy_test\": accuracy_test,\n",
    "      \"f1_test\": f1_test,\n",
    "      \"precision_test\": precision_test,\n",
    "      \"recall_test\": recall_test,\n",
    "      \"loss_test\": loss_test\n",
    "   }\n",
    "\n",
    "   results_dir = \"./results\"\n",
    "   os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "   results_df = pd.DataFrame([results], columns=results.keys())\n",
    "   results_df.to_csv(os.path.join(results_dir, f\"{model_path}-{train_path}\"), index=False)\n",
    "\n",
    "   print(results_df)\n",
    "   except Exception as error:\n",
    "      print(f'Error : {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d9daf-219e-4f84-9c08-866423ca4c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
