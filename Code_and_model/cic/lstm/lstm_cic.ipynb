{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f78392-dbd4-4a8a-92cc-feafd9c918fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single device: GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import shutil\n",
    "import requests, json\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, log_loss\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "botnum = 0\n",
    "bot = ['https://discord.com/api/webhooks/1162767976034996274/B6CjtQF1SzNRalG_csFx8-qJ5ODBoy5SBUelbGyl-v-QhYhwdsTfE59F-K-rXj3HyUh-',\n",
    "      'https://discord.com/api/webhooks/1162767979658887299/0TICfekiC9wjPmp-GqE5zrwU57q2RJHG2peel_KOYagUDYCjovYUfyNJmDR9jbD-WXoE']\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"GPU:0\")\n",
    "    print('Single device: GPU:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscordNotificationCallback(Callback):\n",
    "    def __init__(self, webhook_url, interval=1):\n",
    "        super().__init__()\n",
    "        self.webhook_url = webhook_url\n",
    "        self.interval = interval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.interval == 0:\n",
    "            if logs is not None:\n",
    "                loss = logs.get('loss')\n",
    "                accuracy = logs.get('accuracy')\n",
    "                val_loss = logs.get('val_loss')\n",
    "                val_accuracy = logs.get('val_accuracy')\n",
    "                message = f\"LSTM-CIC -> Epoch: {epoch}, Loss: {loss}, Accuracy: {accuracy}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\"\n",
    "                payload = {\"content\": message}\n",
    "                headers = {\"Content-Type\": \"application/json\"}\n",
    "                response = requests.post(self.webhook_url, data=json.dumps(payload), headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eeef76-95a5-4401-a34e-71f98a679efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processlabel(df):\n",
    "    df.loc[df['label'] == 'BENIGN', 'label'] = 0\n",
    "    df.loc[df['label'] != 0, 'label'] = 1\n",
    "    df['label'] = df['label'].astype('int')\n",
    "    return df\n",
    "    \n",
    "def preprocess(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "def send_discord_message(content):\n",
    "    webhook_url = bot[botnum]\n",
    "\n",
    "    data = {\n",
    "        'content': content\n",
    "    }\n",
    "\n",
    "    response = requests.post(webhook_url, data=json.dumps(data), headers={'Content-Type': 'application/json'})\n",
    "\n",
    "    if response.status_code != 204:\n",
    "        raise ValueError(f'Request to discord returned an error {response.status_code}, the response is:\\n{response.text}')\n",
    "\n",
    "def create_LSTM(n_input, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10,return_sequences=False, input_shape =(n_input, n_features)))\n",
    "    model.add(Dropout(0.3))\n",
    "    # model.add(LSTM(256,return_sequences=True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(256,return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer ='adam', loss = 'BinaryCrossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffa985-a404-4d30-bbdd-a179b7c889e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dir = train_path.split('/')\n",
    "# df = pd.read_csv(f'./dataset/all_dataset/imap.csv')\n",
    "# df.label.value_counts()\n",
    "# df = processlabel(df)\n",
    "\n",
    "# X = df.drop(['label'], axis =1)\n",
    "# X = preprocess(X)\n",
    "# y = df['label']\n",
    "\n",
    "# window_size = 128\n",
    "# n_features = 41\n",
    "# train_size = int(len(X) * 0.7)\n",
    "\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# train_generator = TimeseriesGenerator(X_train, y_train, length = window_size, batch_size =8)\n",
    "# train_generator = TimeseriesGenerator(X_test, y_test, length = window_size, batch_size =8)\n",
    "\n",
    "# model = create_LSTM(window_size, n_features)\n",
    "# model.summary()\n",
    "# model.fit(generator, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/cic/')\n",
    "df_list = glob.glob('/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/cic/dataset/label_dataset/*.csv')\n",
    "dataset = {}\n",
    "\n",
    "model_path = './lstm/model'\n",
    "csv_path = './lstm/results'\n",
    "if not os.path.exists(model_path):\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(model_path)\n",
    "   print(f\"The {model_path} directory is created!\")\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(csv_path)\n",
    "   print(f\"The {csv_path} directory is created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0f880-3e44-4363-9616-6839e1578dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/cic/lstm/lstm_cic.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkagayaki/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/cic/lstm/lstm_cic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdir\u001b[39m \u001b[39m=\u001b[39m train_path\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkagayaki/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/cic/lstm/lstm_cic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39mdir\u001b[39m[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkagayaki/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/cic/lstm/lstm_cic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./dataset/train_dataset/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfile_name\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkagayaki/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/cic/lstm/lstm_cic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m df \u001b[39m=\u001b[39m processlabel(df)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkagayaki/home/s2316002/ML-Based-Adaptive-Cybersecurity-Incident-Detection/Code_and_model/cic/lstm/lstm_cic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m X \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m], axis \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m         nrows\n\u001b[1;32m   1706\u001b[0m     )\n\u001b[1;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Training and evaluation\n",
    "\n",
    "for train_path in df_list:\n",
    "\n",
    "   #Loading Dataset & Preprocess\n",
    "   dir = train_path.split('/')\n",
    "   file_name = dir[-1]\n",
    "   df = pd.read_csv(f'./dataset/train_dataset/{file_name}')\n",
    "   df = processlabel(df)\n",
    "    \n",
    "   X = df.drop(['label'], axis =1)\n",
    "   X = preprocess(X)\n",
    "   y = df['label']\n",
    "\n",
    "   #Creating callbacks\n",
    "   save_model_path = f'./lstm/model/{file_name}.ckpt'\n",
    "\n",
    "   discord_callback = DiscordNotificationCallback(bot[botnum], interval=1)\n",
    "   earlyStopping = EarlyStopping(monitor='val_loss', patience=1, verbose=0, mode='min')\n",
    "   best_model = ModelCheckpoint(save_model_path, save_best_only=True, monitor='val_loss', mode='min')\n",
    "   if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "      X = X.values\n",
    "\n",
    "   if isinstance(y, (pd.DataFrame, pd.Series)):\n",
    "      y = y.values\n",
    "\n",
    "   #Setting parameter\n",
    "   window_size = 128\n",
    "   n_features = df.shape[-1] -1\n",
    "   train_size = int(len(X) * 0.7)\n",
    "    \n",
    "   X_train, X_test = X[:train_size], X[train_size:]\n",
    "   y_train, y_test = y[:train_size], y[train_size:]\n",
    "   \n",
    "   train_generator = TimeseriesGenerator(X_train, y_train, length = window_size, batch_size = 8)\n",
    "   test_generator = TimeseriesGenerator(X_test, y_test, length = window_size, batch_size=len(X_test)-window_size)\n",
    "    \n",
    "   model = create_LSTM(window_size, n_features)\n",
    "\n",
    "   #Summary of Model\n",
    "   model.summary()\n",
    "   try:\n",
    "      model.fit(train_generator, \n",
    "               epochs=10,\n",
    "               callbacks= [discord_callback, best_model, earlyStopping],\n",
    "               validation_data=test_generator)  \n",
    "      \n",
    "      evaluation_model = create_LSTM(window_size, n_features)\n",
    "      evaluation_model.load_weights(save_model_path)\n",
    "\n",
    "      # Evaluate the model using the test generator sequences\n",
    "      X_test_sequences, y_test_sequences = test_generator[0]\n",
    "      y_pred_prob_test = evaluation_model.predict(test_generator)\n",
    "      y_pred_test = (y_pred_prob_test > 0.5).astype(int)\n",
    "\n",
    "      accuracy_test = accuracy_score(y_test_sequences, y_pred_test)\n",
    "      f1_test = f1_score(y_test_sequences, y_pred_test)\n",
    "      precision_test = precision_score(y_test_sequences, y_pred_test)\n",
    "      recall_test = recall_score(y_test_sequences, y_pred_test)\n",
    "      loss_test = log_loss(y_test_sequences, y_pred_prob_test)\n",
    "\n",
    "      # Save results\n",
    "      results = {\n",
    "         \"accuracy_test\": accuracy_test,\n",
    "         \"f1_test\": f1_test,\n",
    "         \"precision_test\": precision_test,\n",
    "         \"recall_test\": recall_test,\n",
    "         \"loss_test\": loss_test\n",
    "      }\n",
    "\n",
    "\n",
    "      results_df = pd.DataFrame([results], columns=results.keys())\n",
    "      results_df.to_csv(f\"./lstm/results/{file_name}.csv\", index=False)\n",
    "\n",
    "      print(results_df)\n",
    "   except Exception as error:\n",
    "      print(f'Error : {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d9daf-219e-4f84-9c08-866423ca4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf = pd.read_csv('./dataset/label_dataset/Bot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b966d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b12078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
