{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7bc9fdb-8b16-44ea-9817-197dd37cc733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== reading training data: /home/s2316002/capstone_project/kdd/dataset/all_dataset/snmpgetattack.csv ==\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "StratifiedShuffleSplit.__init__() got an unexpected keyword argument 'n_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m train_df \u001b[38;5;241m=\u001b[39m preprocess(X)\n\u001b[1;32m     93\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 94\u001b[0m sss \u001b[38;5;241m=\u001b[39m \u001b[43mStratifiedShuffleSplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m n_split = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msss\u001b[38;5;241m.\u001b[39mget_n_splits(X,y)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     97\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mTypeError\u001b[0m: StratifiedShuffleSplit.__init__() got an unexpected keyword argument 'n_iter'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "import glob\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from joblib import dump\n",
    "os.chdir('/home/s2316002/capstone_project/kdd/classical_ML')\n",
    "botnum = 1\n",
    "bot = ['https://discord.com/api/webhooks/1162767976034996274/B6CjtQF1SzNRalG_csFx8-qJ5ODBoy5SBUelbGyl-v-QhYhwdsTfE59F-K-rXj3HyUh-',\n",
    "      'https://discord.com/api/webhooks/1162767979658887299/0TICfekiC9wjPmp-GqE5zrwU57q2RJHG2peel_KOYagUDYCjovYUfyNJmDR9jbD-WXoE']\n",
    "\n",
    "def processlabel(df):\n",
    "    df.loc[df['label'] == 'normal', 'label'] = 0\n",
    "    df.loc[df['label'] != 0, 'label'] = 1\n",
    "    df['label'] = df['label'].astype('int')\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "    return df\n",
    "\n",
    "def send_discord_message(content):\n",
    "    webhook_url = bot[botnum]\n",
    "\n",
    "    data = {\n",
    "        'content': content\n",
    "    }\n",
    "\n",
    "    response = requests.post(webhook_url, data=json.dumps(data), headers={'Content-Type': 'application/json'})\n",
    "\n",
    "    if response.status_code != 204:\n",
    "        raise ValueError(f'Request to discord returned an error {response.status_code}, the response is:\\n{response.text}')\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=10000, n_jobs=-1),\n",
    "    # 'LinearSVM': SVC(kernel=\"linear\", probability=True),  # SVC does not support n_jobs\n",
    "    # 'RBFSVM': SVC(kernel=\"rbf\", probability=True),  # SVC does not support n_jobs\n",
    "    'ExtraTrees': ExtraTreesClassifier(n_jobs=-1),\n",
    "    'Bagging': BaggingClassifier(estimator=DecisionTreeClassifier(), n_jobs=-1),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),  # Single decision tree does not support n_jobs\n",
    "    'RandomForest': RandomForestClassifier(n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),  # GradientBoosting does not support n_jobs\n",
    "    'KNeighbors': KNeighborsClassifier(n_jobs=-1),\n",
    "    'GaussianNB': GaussianNB(),  # GaussianNB does not support n_jobs\n",
    "    'Perceptron': Perceptron(n_jobs=-1),\n",
    "    'AdaBoost': AdaBoostClassifier()  # AdaBoost does not support n_jobs\n",
    "}\n",
    "\n",
    "dataset_paths = glob.glob('/home/s2316002/capstone_project/kdd/dataset/all_dataset/*.csv')\n",
    "\n",
    "# Lists to store metrics\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "cms = []\n",
    "FPRs = []\n",
    "FNRs = []\n",
    "TPRs = []\n",
    "TNRs = []\n",
    "\n",
    "datasets = {train_path.split('/')[-1]: (train_path, train_path) for train_path in dataset_paths}\n",
    "\n",
    "for dataset_name, (train_path, _) in datasets.items():\n",
    "    print(f\"== reading training data: {train_path} ==\")\n",
    "    df = pd.read_csv(train_path)\n",
    "    df = processlabel(df)\n",
    "    \n",
    "    X = df.drop('label', axis=1)\n",
    "    train_df = preprocess(X)\n",
    "    \n",
    "    y = df['label']\n",
    "    sss = StratifiedShuffleSplit(random_state=42, test_size=0.3, n_iter=1)         # Cross varidation <----- to be use (optional)\n",
    "    print(f' n_split = {sss.get_n_splits(X,y)}')\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(sss.split(X,y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        for name, model in models.items():\n",
    "            try:\n",
    "                \n",
    "                print(f\"== Training: {train_path.split('/')[-1]} with model: {name} ==\")\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "        \n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred, zero_division = 1)\n",
    "                precision = precision_score(y_test, y_pred, zero_division = 1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division = 1)\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                if conf_matrix.size == 1:\n",
    "                    TN, FP, FN, TP = 0, 0, 0, conf_matrix[0][0]\n",
    "                else:\n",
    "                    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "                \n",
    "                conf_matrix_path = f\"/home/s2316002/capstone_project/kdd/classical_ML/confusion_martix/{train_path.split('/')[-1]}\"\n",
    "                if not os.path.exists(conf_matrix_path):\n",
    "                    os.makedirs(conf_matrix_path)\n",
    "                    \n",
    "                plt.figure()\n",
    "                sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "                plt.xlabel('Predicted')\n",
    "                plt.ylabel('Actual')\n",
    "                plt.title('Confusion Matrix')\n",
    "                plt.savefig(f\"/home/s2316002/capstone_project/kdd/classical_ML/confusion_martix/{train_path.split('/')[-1]}/{train_path.split('/')[-1]}_{name}_confusion_matrix.png\")\n",
    "                plt.close()\n",
    "        \n",
    "                loss = np.mean(np.abs(y_pred - y_test))\n",
    "                print(f\"== Done Training: {train_path.split('/')[-1]} with model: {name}, acc: {accuracy}, loss: {loss}, f1: {f1} ==\")\n",
    "                models_save_path = f\"/home/s2316002/capstone_project/kdd/classical_ML/model/{train_path.split('/')[-1]}\"\n",
    "                if not os.path.exists(models_save_path):\n",
    "                    os.makedirs(models_save_path)\n",
    "        \n",
    "                model_filename = os.path.join(models_save_path, f\"/home/s2316002/capstone_project/kdd/classical_ML/model/{train_path.split('/')[-1]}/{train_path.split('/')[-1]}_{name}_model.joblib\")\n",
    "                dump(model, model_filename)\n",
    "                print(f\"== Model {name} saved as {model_filename} ==\")\n",
    "                \n",
    "                results[name] = [accuracy, loss, f1, precision, recall, conf_matrix]\n",
    "            except Exception as error:\n",
    "                print(f'==== {error} ====')\n",
    "\n",
    "    result_df = pd.DataFrame.from_dict(results, orient='index', columns=['accuracy', 'loss', 'f1', 'precision', 'recall', 'confusion_matrix'])\n",
    "    result_filename = f\"/home/s2316002/capstone_project/kdd/classical_ML/compare/evaluation_results_{train_path.split('/')[-1]}\"\n",
    "    result_df.to_csv(result_filename)\n",
    "    \n",
    "send_discord_message('== @everyone All training and evaluation in KDD is done ==')\n",
    "print('== @everyone All training and evaluation is done ==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372cdf06-50b8-4ad4-bfb8-2401107f7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = pd.read_csv('/home/s2316002/capstone_project/kdd/dataset/all_dataset/spy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff88203a-f5ef-4154-8340-e1d55756ad3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "normal    77054\n",
       "spy           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"== reading training data: {train_path} ==\")\n",
    "df = pd.read_csv(train_path)\n",
    "df = processlabel(df)\n",
    " \n",
    "X = df.drop('label', axis=1)\n",
    "train_df = preprocess(X)\n",
    "    \n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596b52b2-66ee-4854-be08-88bbded2f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytemp = processlabel(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be2f631-64f5-4df4-acf0-e4e1a8e73b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    77054\n",
       "1        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytemp.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6cfebf-0cdf-489f-8ef7-86949f793f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
