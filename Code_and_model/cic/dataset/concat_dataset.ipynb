{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7934698-3c5f-4534-b1f6-b939d1b3870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd \n",
    "import codecs\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8452f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Kotani Lab\\\\Desktop\\\\ML_senior_project\\\\ML-Based-Adaptive-Cybersecurity-Incident-Detection\\\\Code_and_model\\\\cic\\\\dataset\\\\Original_dataset-notuse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24d00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_utf8(filename: str, encoding=\"latin1\", blocksize=1048576):\n",
    "    tmpfilename = filename + \".tmp\"\n",
    "    with codecs.open(filename, \"r\", encoding) as source:\n",
    "        with codecs.open(tmpfilename, \"w\", \"utf-8\") as target:\n",
    "            while True:\n",
    "                contents = source.read(blocksize)\n",
    "                if not contents:\n",
    "                    break\n",
    "                target.write(contents)\n",
    "    os.rename(filename, filename + '_old')\n",
    "    # replace the original file\n",
    "    os.rename(tmpfilename, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8440e2-3884-4a72-8a87-6ec3738c2442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kotani Lab\\AppData\\Local\\Temp\\ipykernel_15460\\1739749492.py:10: DtypeWarning: Columns (0,1,3,6,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df6=pd.read_csv(file_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table has 3119345 rows and 85 columns\n"
     ]
    }
   ],
   "source": [
    "os.remove('Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv_old')\n",
    "df1=pd.read_csv(\"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "df2=pd.read_csv(\"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\")\n",
    "df3=pd.read_csv(\"Friday-WorkingHours-Morning.pcap_ISCX.csv\")\n",
    "df4=pd.read_csv(\"Monday-WorkingHours.pcap_ISCX.csv\")\n",
    "df5=pd.read_csv(\"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\")\n",
    "\n",
    "file_name = \"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\"\n",
    "_to_utf8(file_name)\n",
    "df6=pd.read_csv(file_name)\n",
    "\n",
    "df7=pd.read_csv(\"Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "df8=pd.read_csv(\"Wednesday-workingHours.pcap_ISCX.csv\")\n",
    "\n",
    "\n",
    "df = pd.concat([df1,df2])\n",
    "del df1,df2\n",
    "df = pd.concat([df,df3])\n",
    "del df3\n",
    "df = pd.concat([df,df4])\n",
    "del df4\n",
    "df = pd.concat([df,df5])\n",
    "del df5\n",
    "df = pd.concat([df,df6])\n",
    "del df6\n",
    "df = pd.concat([df,df7])\n",
    "del df7\n",
    "df = pd.concat([df,df8])\n",
    "del df8\n",
    "gc.collect()\n",
    "nRow, nCol = df.shape\n",
    "print(f'The table has {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42832fcf-8201-4a49-8a2c-0d1e647ddc9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def categorize_port(port):\n",
    "    if 0 <= port <= 1023:\n",
    "        return 1\n",
    "    elif 1024 <= port <= 49151:\n",
    "        return 2\n",
    "    elif 49152 <= port <= 65535:\n",
    "        return 3\n",
    "    else:\n",
    "        return None  # or however you want to handle out-of-range values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30022c63-8baa-4296-bd1e-b1b0689b3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = []\n",
    "for i, name in enumerate(df.columns):\n",
    "    if name[0] == ' ':\n",
    "        name = name[1:]\n",
    "    if ' ' in name:\n",
    "        name = name.replace(' ', '_')\n",
    "    col_list.append(name)\n",
    "df.columns = col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c138d0-c6b9-4df6-b9d1-b7879dd498a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Destination_Port'] = df['Destination_Port'].apply(categorize_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273333e6-5f91-4173-9aff-adf91ce80670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns containing NaN values: []\n"
     ]
    }
   ],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "cols_with_nan = df.columns[df.isna().any()].tolist()\n",
    "print(\"Columns containing NaN values:\", cols_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6f384c-71e7-442a-85f4-1cd04d79cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = df.columns.tolist()\n",
    "list = [x.lower() for x in list]\n",
    "df.columns = list\n",
    "df = df.rename(columns = {'destination_port': 'destination_port_priority'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cab99063-c36f-45c4-8a99-c9c75445541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot encode the 'destination_port_priority' column\n",
    "temp = pd.get_dummies(df['destination_port_priority'], prefix='destination_port_priority', dtype=int)\n",
    "\n",
    "# Drop the original 'destination_port_priority' column and append the dummies\n",
    "df = df.drop('destination_port_priority', axis=1).join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f46024-240f-49b5-861b-ca3780cfa2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed94f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _renaming_class_label(df: pd.DataFrame):\n",
    "    labels = {\"Web Attack \\x96 Brute Force\": \"Web Attack-Brute Force\",\n",
    "              \"Web Attack \\x96 XSS\": \"Web Attack-XSS\",\n",
    "              \"Web Attack \\x96 Sql Injection\": \"Web Attack-Sql Injection\"}\n",
    "\n",
    "    for old_label, new_label in labels.items():\n",
    "        df.label.replace(old_label, new_label, inplace=True)\n",
    "\n",
    "# Renaming labels\n",
    "_renaming_class_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f0185f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          7/7/2017 3:30\n",
       "0          7/7/2017 3:30\n",
       "0          7/7/2017 3:30\n",
       "0          7/7/2017 3:30\n",
       "0          7/7/2017 3:30\n",
       "               ...      \n",
       "692698    5/7/2017 12:10\n",
       "692699     5/7/2017 3:02\n",
       "692700    5/7/2017 10:06\n",
       "692701     5/7/2017 1:19\n",
       "692702     5/7/2017 2:43\n",
       "Name: timestamp, Length: 16601424, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33d5f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Kotani Lab\\\\Desktop\\\\ML_senior_project\\\\ML-Based-Adaptive-Cybersecurity-Incident-Detection\\\\Code_and_model\\\\cic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4142ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/Original_dataset-notuse/CIC_IDS2017.csv', low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "df = df.sort_values(by='timestamp')\n",
    "non_numerical_columns = df.select_dtypes(exclude=['number']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c26db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['source_port'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec34524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(non_numerical_columns.drop(['label', 'timestamp']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407038f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd8976-cd6a-44e1-a47a-24560062a3f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('CIC_IDS2017.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bcdc1f-a23c-49dc-956c-de97ae180b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Kotani Lab\\\\Desktop\\\\ML_senior_project\\\\ML-Based-Adaptive-Cybersecurity-Incident-Detection\\\\Code_and_model\\\\cic\\\\dataset\\\\Original_dataset-notuse'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b9022-45cf-4a15-a0dc-2cd71c74bf5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m file \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCIC_IDS2017.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m         nrows\n\u001b[0;32m   1750\u001b[0m     )\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv('../mix_dataset/Bot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af94eb65-1cd2-4a5a-81b6-6314fc3ebc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
