{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9738600-6840-4db0-88b8-dc52db36c6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Kotani Lab\\\\Desktop\\\\ML_senior_project\\\\ML-Based-Adaptive-Cybersecurity-Incident-Detection\\\\Code_and_model\\\\Program'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf171c2-cb6c-44ec-a445-824197514581",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd1 = pd.read_csv('kdd/Result/kdd1/attack_prediction_kdd.csv')\n",
    "kdd2 = pd.read_csv('kdd/Result/kdd2/attack_prediction_kdd.csv')\n",
    "cic1 = pd.read_csv('cic/Result/cic1/attack_prediction_cic.csv')\n",
    "cic2 = pd.read_csv('cic/Result/cic2/attack_prediction_cic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dbf42b-ec66-475d-9da5-c6edd4edc828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred1 = kdd1.Prediction\n",
    "y_pred2 = kdd2.Prediction\n",
    "y_pred3 = cic1.Prediction\n",
    "y_pred4 = cic2.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f405ff82-a801-4419-9d1e-94926d027549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_kdd = pd.read_csv(glob.glob(f'kdd/train_test_folder/test_kdd/*')[0])\n",
    "df_test_cic = pd.read_csv(glob.glob(f'cic/train_test_folder/test_cic/*')[0])\n",
    "\n",
    "test_labels_kdd = df_test_kdd['label']\n",
    "test_labels_cic = df_test_cic['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f21ef-3db1-4551-be60-329e4158d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adaptive(test_labels, y_detect_bi, data_template):\n",
    "    # print(f'test_labels1 : {test_labels}')\n",
    "    for i, j in enumerate(y_detect_bi):\n",
    "        if j == 0:\n",
    "            if data_template == 'cic':\n",
    "                test_labels.iloc[i] = 'BENIGN'\n",
    "            else:\n",
    "                test_labels.iloc[i] = 'normal'\n",
    "    return test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33e1602-c38f-499c-92b6-95b64d8d9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(test_labels, y_pred, template):\n",
    "    # Initialize an empty list to store the converted labels\n",
    "    converted_labels = []\n",
    "    \n",
    "    # Iterate through both the test labels and predictions\n",
    "    for label, pred in zip(test_labels, y_pred):\n",
    "        if pred == 0 and template == 'kdd':\n",
    "            converted_labels.append('normal')\n",
    "        elif pred == 0 and template == 'cic':\n",
    "            converted_labels.append('BENIGN')\n",
    "        else:\n",
    "            converted_labels.append(label)\n",
    "    \n",
    "    # Create a new DataFrame from the converted labels\n",
    "    converted_df = pd.DataFrame(converted_labels, columns=['label'])\n",
    "    \n",
    "    return converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc43d0-fba8-44ee-a577-a9290923fdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bb1c0e4-6c86-4aa2-bad0-155c3b387ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converted_df1 = convert_labels(test_labels_kdd, y_pred1, 'kdd')\n",
    "converted_df2 = convert_labels(test_labels_kdd, y_pred2, 'kdd')\n",
    "converted_df3 = convert_labels(test_labels_cic, y_pred3, 'cic')\n",
    "converted_df4 = convert_labels(test_labels_cic, y_pred4, 'cic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "202a5e7f-8360-4c76-8ca3-46f1b353f76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDD1 : \n",
      "label\n",
      "normal      44554\n",
      "multihop        1\n",
      "rootkit         1\n",
      "Name: count, dtype: int64\n",
      "KDD2 : \n",
      "label\n",
      "normal       40406\n",
      "satan         1278\n",
      "ipsweep       1108\n",
      "portsweep      922\n",
      "nmap           465\n",
      "mscan          296\n",
      "saint           81\n",
      "Name: count, dtype: int64\n",
      "CIC1 : \n",
      "label\n",
      "BENIGN                      847745\n",
      "Web Attack-Brute Force         432\n",
      "Web Attack-XSS                 179\n",
      "Web Attack-Sql Injection         5\n",
      "PortScan                         1\n",
      "DoS GoldenEye                    1\n",
      "Name: count, dtype: int64\n",
      "CIC2 : \n",
      "label\n",
      "BENIGN                      734615\n",
      "DoS Hulk                     68918\n",
      "DDoS                         38392\n",
      "DoS GoldenEye                 3075\n",
      "DoS slowloris                 1730\n",
      "DoS Slowhttptest              1627\n",
      "PortScan                         5\n",
      "Web Attack-Sql Injection         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'KDD1 : \\n{converted_df1.label.value_counts()}')\n",
    "print(f'KDD2 : \\n{converted_df2.label.value_counts()}')\n",
    "print(f'CIC1 : \\n{converted_df3.label.value_counts()}')\n",
    "print(f'CIC2 : \\n{converted_df4.label.value_counts()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1e81a-c768-4955-bd21-3cca28ef0573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48be2ee-6ed9-4028-a130-7d6a771abb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd1_count = calculate_adaptive(test_labels_kdd, y_detect_bi, 'kdd')\n",
    "kdd2_count = calculate_adaptive(test_labels_kdd, y_detect_bi, 'kdd')\n",
    "cic1_count = calculate_adaptive(test_labels_cic, y_detect_bi, 'cic')\n",
    "cic2_count = calculate_adaptive(test_labels_cic, y_detect_bi, 'cic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30772f7-49aa-4b9d-a65a-5c4c569a1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "window_size = 64\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "n_features = X_main.shape[1]\n",
    "\n",
    "DL_args = [window_size, batch_size, epochs]\n",
    "\n",
    "chunk_size = 200\n",
    "X = traindf.drop('label', axis=1)\n",
    "y = traindf['label']\n",
    "\n",
    "Data = TimeseriesGenerator(X, y, length=window_size, sampling_rate=1, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116d04f-1f77-4952-9e21-9a51b38f9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_models(window_size, n_features):\n",
    "\n",
    "    models = {\n",
    "        'LSTM' : lstm(window_size, n_features)\n",
    "    }\n",
    "\n",
    "    return models\n",
    "\n",
    "def lstm(window_size, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(window_size, n_features), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = RMSprop(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "models = sequential_models(window_size, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee8349-3810-400f-b41d-877ea2467a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07f7ee-ef98-4ab2-bab1-51f786f00db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db9e5b-c745-4b10-a2a6-a48d59d1b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(Data, train_index, test_index, batch_size, window_size, chunk_size=200):\n",
    "    def rearrange_sequences(generator, index, batch_size, window_size):\n",
    "        rearranged_data = []\n",
    "\n",
    "        for idx in tqdm(index, desc=\"Processing sequences\"):\n",
    "            if idx >= window_size - 1:  # Ensure index has enough preceding samples for a full sequence\n",
    "                sequence_end = idx + 1  # Sequence ends at the current index (inclusive)\n",
    "                sequence_start = sequence_end - window_size  # Sequence starts 'window_size' samples before the end\n",
    "\n",
    "                batch_x = generator.data[sequence_start:sequence_end]  # Extract feature sequence\n",
    "                batch_y = generator.targets[idx]  # Corresponding label\n",
    "\n",
    "                rearranged_data.append((batch_x, batch_y))\n",
    "\n",
    "        return rearranged_data\n",
    "    # Process training data\n",
    "    print('Training data processing...')\n",
    "    train_data = rearrange_sequences(Data, train_index, batch_size, window_size)\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Testing data processing...')\n",
    "    test_data = rearrange_sequences(Data, test_index, batch_size, window_size)\n",
    "    del rearrange_sequences\n",
    "    gc.collect()\n",
    "    return train_data, test_data\n",
    "    \n",
    "def separate_features_labels(data, window_size):\n",
    "    features = np.array([item[0] for item in data], dtype=np.float32)  # item[0] is each sequence\n",
    "    labels = np.array([item[1] for item in data], dtype=np.float32)  # item[1] is the corresponding label\n",
    "\n",
    "    # Ensure features are reshaped to (number_of_sequences, window_size, number_of_features_per_timestep)\n",
    "    features = features.reshape(-1, window_size, features.shape[-1])\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def training_DL(models, df, DL_args, train_test_index):\n",
    "    results = {}\n",
    "    X = df.drop('label', axis=1)\n",
    "    y = df['label']\n",
    "    \n",
    "    window_size, batch_size, epochs = DL_args\n",
    "    \n",
    "    Data = TimeseriesGenerator(X, y, length=window_size, sampling_rate=1, batch_size=batch_size)\n",
    "    print(f'Data type {type(Data)}')\n",
    "    train_index, test_index = train_test_index\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    print('Processing Training data...')\n",
    "    \n",
    "    train_data, test_data = process_data(Data, train_index, test_index, batch_size, window_size)\n",
    "    gc.collect()\n",
    "    X_train, y_train = separate_features_labels(train_data, window_size)\n",
    "    X_test, y_test = separate_features_labels(test_data, window_size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277b199-068b-4450-ae27-46a6e93cee99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data = TimeseriesGenerator(X, y, length=window_size, sampling_rate=1, batch_size=batch_size)\n",
    "print(f'Data type {type(Data)}')\n",
    "train_index, test_index = train_test_index\n",
    "print('Processing Training data...')\n",
    "\n",
    "X_train, X_test, y_train, y_test = training_DL(models, traindf, DL_args, train_test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a415a41-f880-4574-8a49-08e2d39c65ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# window_size = 64\n",
    "# batch_size = 4\n",
    "# epochs = 10\n",
    "X_train[0][63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7fb1e6-eae3-487e-bbd1-22afe945af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_index[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e018212-b759-405a-bfcd-8b5f0c908155",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b7191-bb09-4eec-bdd7-4a8c3b42f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2f121-f4eb-465a-a324-381c64efd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622ffb2-3c6b-4aa7-bb87-5c5b9144d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc3bf4a-c896-4c34-82f1-2839520ca225",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7244fe-ec46-4986-9fa0-b68e8f216d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8baf76-0e2e-4cbd-aad4-f9a202112c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_start_index = train_test_index[0][1] - (window_size - 1)\n",
    "sequence_start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e969a-d408-4183-b4ff-24b6a74a1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = sequence_start_index // batch_size\n",
    "batch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a782ddc-62a1-4221-837a-f2e44e2f90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_within_batch = sequence_start_index % batch_size\n",
    "position_within_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab6a2d-c6e9-415b-b377-5a04429b2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data point\n",
    "array = traindf.drop('label', axis=1).iloc[train_test_index[0][1]].to_numpy()\n",
    "\n",
    "# Data from the generator\n",
    "datagen = Data[batch_index][0][0][window_size-1]\n",
    "\n",
    "# Comparison\n",
    "equal = np.array_equal(array, datagen)\n",
    "equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce1fc3-2b06-4365-ab4e-9fc1dc1763f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "files = glob.glob(f'kdd/Training/model/**', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848162c4-c1e0-4e55-a67e-39b45d0294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'kdd/Training/model/**', recursive=True)\n",
    "for file in files:\n",
    "    if 'LSTM' in file:\n",
    "        text1 = file.split('/')\n",
    "        text2 = file.split('\\\\')\n",
    "        model = text2[1]\n",
    "        print(model)\n",
    "        newname = file.replace('LSTM',f'{model}_LSTM_model')\n",
    "        print(newname)\n",
    "        os.rename(file,newname)\n",
    "        print(f'Changing {file} with {newname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443377d5-6a6a-4d10-8db2-9ac372df81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'kdd/Training/model/**', recursive=True)\n",
    "for file in files:\n",
    "    if 'LSTM' in file:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d4c36-9669-4667-9160-1625e9bdd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23fa95-269c-46c5-a251-c175c8acc9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('kdd/Training/model\\land\\LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4212539-5bf7-4256-ba18-a2d082198945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504c3b5-6e65-4f74-93a9-d972e0663710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cic/CIC_IDS2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7378e6b-d2cf-4d3a-89df-80f915d9ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51493e7-ba61-4cd8-851e-d899f04d36ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./cic/train_test_folder/train_cic/train.csv')\n",
    "df2 = pd.read_csv('./cic/train_test_folder/test_cic/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc01b2-1fab-43a0-8425-a416b0e16a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66db06-4306-4c4b-9b7d-011dfb6e4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "1979513 + 848363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024ccf9-51e1-4ef1-8fb7-c11f433f72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./kdd/KDD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746cac8-e968-4590-a3d5-26816fed73bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a3b2b-a732-4fb8-a4db-71d7dde3b896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
